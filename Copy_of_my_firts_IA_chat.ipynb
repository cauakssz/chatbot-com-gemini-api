{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U -q google-generativeai"
      ],
      "metadata": {
        "id": "gl9iA2yEiRM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbB0i3fScXJy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        " if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "I0N9AGbog4IS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "6294a7d1-5a33-47b6-b4c5-6905cf13e98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "hRFo0egKlAen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "wd4BLNRjlcR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "rw94rngKm8eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-latest\",\n",
        "                              safety_settings=safety_settings,\n",
        "                              generation_config=generation_config)"
      ],
      "metadata": {
        "id": "QF97mfrD0C2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f5mTZ7qbTIwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])\n",
        "response = chat.send_message(\"Olá!\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "V3pvg4Zv2xfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "25282145-2ce3-4e87-b29d-a59e89f40693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá! Como posso te ajudar hoje?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "3vG0smTq4G0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Imports no início do código\n",
        "import textwrap\n",
        "import time\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# 2. Sua função de formatação\n",
        "def to_markdown(text):\n",
        "  \"\"\"Formata o texto para exibição como Markdown com citação.\"\"\"\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# 3. Inicialização do Chat (supondo que a variável 'model' já existe)\n",
        "chat = model.start_chat(history=[])\n",
        "print(\"Você: Jarvis, consegue me ajudar?\")\n",
        "print(\"\")\n",
        "print(\"Jarvis: Como posso ajudar?\")\n",
        "print(\"\")\n",
        "\n",
        "# 4. Loop de Chat Interativo COM a formatação em tempo real\n",
        "prompt = input(\"Você: \")\n",
        "\n",
        "while prompt.lower() != \"dispensar jarvis\":\n",
        "  # Envia a mensagem para o modelo\n",
        "  response = chat.send_message(prompt)\n",
        "\n",
        "  # Exibe a resposta do modelo JÁ FORMATADA\n",
        "  print(\"\\nJarvis:\")\n",
        "  display(to_markdown(response.text))\n",
        "  print(\"-------------------------------------------\")\n",
        "\n",
        "  # (Opcional) Pequena pausa para não sobrecarregar\n",
        "  time.sleep(1)\n",
        "\n",
        "  # Pede o próximo input\n",
        "  prompt = input(\"Você: \")\n",
        "\n",
        "print(\"\\nJarvis: Tudo bem, fico feliz em ajudar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBu_OIRJ4jEq",
        "outputId": "02ce4a35-306a-46f5-d343-4a25d744cde4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Você: Jarvis, consegue me ajudar?\n",
            "\n",
            "Jarvis: Como posso ajudar?\n",
            "\n",
            "Você: dispensar jarvis\n",
            "\n",
            "Jarvis: Tudo bem, fico feliz em ajudar.\n"
          ]
        }
      ]
    }
  ]
}